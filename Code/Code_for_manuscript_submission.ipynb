{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Date for documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Get Time and Data for documentation '''\n",
    "def get_date_yyyymmdd():\n",
    "    import datetime\n",
    "    date = datetime.datetime.now()\n",
    "    day = str(date.day)\n",
    "    month = str(date.month)\n",
    "    year = str(date.year)\n",
    "    if len(day) <= 1:\n",
    "        day = '0' + day\n",
    "    if len(month) <= 1:\n",
    "        month = '0' + month\n",
    "        \n",
    "    return year+month+day\n",
    "\n",
    "date = get_date_yyyymmdd()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Files Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''VT MAP FILES'''\n",
    "VTMAP_data_file_path = r'../Data/VT_MAP_Data_20191219.npz'\n",
    "\n",
    "'''Choose one from below (uncomment one outcome)'''\n",
    "'''VTVF Outcome'''\n",
    "excelSheetPath = r'../Data/VTVF Split.xlsx'\n",
    "output_label = 'VT_VF in 3Y'\n",
    "\n",
    "#OR\n",
    "\n",
    "'''Mortality Outcome'''\n",
    "#excelSheetPath = r'../Data/Mortality split.xlsx'\n",
    "#output_label = 'Mortality'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configurables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Choose number of features to build model'''\n",
    "numberOfFeatures = 40 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_VT_MAP_data(file):\n",
    "    data = np.load(file, allow_pickle = True)\n",
    "    if file.endswith('.npz'):\n",
    "        data = data['data']\n",
    "    data = data.item()\n",
    "    return data\n",
    "\n",
    "data = load_VT_MAP_data(VTMAP_data_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Excel Writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize Writer for Save Data Frames and Results as xlsx file\n",
    "writer = pd.ExcelWriter('../Results/SVC_Results_'+date+'_'+str(numberOfFeatures)+'_features_'+output_label+'.xlsx', engine='xlsxwriter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create function to tranform data into tsfresh format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_tsfresh_input_format(key,value,output):\n",
    "    x = value\n",
    "    x_reshaped = np.reshape(x,(x.shape[0]*x.shape[1],1))\n",
    "    ids = np.reshape(np.asarray([[float(key)*10000 + i]*x.shape[1] for i in range(x.shape[0])]),(x.shape[0]*x.shape[1],1))\n",
    "    time = np.reshape([i for i in range(x.shape[1])]*x.shape[0],(np.prod(x.shape),1))\n",
    "    ids_time = np.append(ids,time,axis = 1)\n",
    "    ids_time = ids_time.astype(int)\n",
    "    x = np.append(ids_time,x_reshaped,axis = 1)\n",
    "    x_df = pd.DataFrame(data = x, columns = ['id','time','voltages'])\n",
    "    ids = np.asarray([[float(key)*10000 + i] for i in range(value.shape[0])])\n",
    "    ids = ids.astype(int)\n",
    "    y_ds = pd.DataFrame(np.append(ids,np.ones((value.shape[0],1))*output,axis = 1),columns = ['id','outcome'])\n",
    "        \n",
    "    return  x_df, y_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform data to tsfresh format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load outcome excel sheet into pd object\n",
    "outcome_sheet_all = pd.ExcelFile(excelSheetPath) \n",
    "\n",
    "#read each sheet into a pd data frame\n",
    "all_df = pd.DataFrame()\n",
    "all_y = pd.DataFrame()\n",
    "for sheet in ['CV1']:#Choose any sheet in the excel sheet to populate the database\n",
    "    sheet_name = sheet\n",
    "    long_term_outcome = pd.read_excel(outcome_sheet_all, sheet_name = sheet)\n",
    "\n",
    "    #iterate through the rows to get the name of each file\n",
    "    for index, row in long_term_outcome.iterrows():\n",
    "        output = row[output_label]#Get Label associated with patient id\n",
    "        patient_name = str(row['patient'])\n",
    "        if patient_name.endswith('_B'):#Some patients have a second file, change for tsfresh format database creation\n",
    "            patient_name = patient_name[:-2] + '.2'\n",
    "        x_df,y = data_to_tsfresh_input_format(patient_name,data[str(row['patient'])],output)\n",
    "        \n",
    "        #Add each file ot entire database\n",
    "        all_df = all_df.append(x_df)\n",
    "        all_y = all_y.append(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extraction using tsfresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import tsfresh commands        \n",
    "from tsfresh import extract_features\n",
    "#extract features without regard to features\n",
    "if not 'extracted_features' in globals():\n",
    "    extracted_features = extract_features(all_df, column_id=\"id\", column_sort='time')\n",
    "\n",
    "#import select feature to choose right features\n",
    "from tsfresh import select_features\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "#impute command in tsfresh works in place to remove -inf,+inf,nan by min,max,median in each feature\n",
    "impute(extracted_features)\n",
    "\n",
    "#make sure y series in in right format and sorted\n",
    "all_y_series = pd.Series(all_y['outcome'].values, index=all_y['id'])\n",
    "all_y_series = all_y_series.sort_index(axis = 0)\n",
    "\n",
    "#sort extracted features by id\n",
    "extracted_features = extracted_features.sort_index(axis = 0)\n",
    "\n",
    "#use tsfresh select feature command to reduce features\n",
    "features_filtered = select_features(extracted_features, all_y_series, ml_task='classification')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove all features with correlation 0.9 or more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop all but one features with correlation of 0.9 or more\n",
    "from drop_corr_features import drop_input_corr_columns\n",
    "features_filtered_no_colnr, to_drop = drop_input_corr_columns(features_filtered, corr_fac = 0.9)\n",
    "features_filtered_no_colnr = features_filtered_no_colnr.dropna(axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardize feature using mean and standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get mean and sd of all columns to standardize data\n",
    "features_mean = features_filtered_no_colnr.mean()\n",
    "features_std = features_filtered_no_colnr.std()\n",
    "features_filtered_no_colnr_norm=((features_filtered_no_colnr-features_mean)/features_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply logistic regression with L1 penalty to choose features (features with highest coefficients in absolute value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use logistic regression with L1 penalty to get features with highest coefficient in absolute value\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg = LogisticRegression(penalty='l1', random_state = 0, solver='liblinear',\n",
    "                             multi_class = 'ovr', C = 0.05, max_iter = 1000).fit(features_filtered_no_colnr_norm, all_y_series)\n",
    "\n",
    "logReg_coef = log_reg.coef_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and test SVM classificaiton model for all CVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize panda dataframe to save results\n",
    "all_y_results = pd.DataFrame()\n",
    "SVM_results_Train = pd.DataFrame()\n",
    "SVM_results_Val = pd.DataFrame()\n",
    "\n",
    "\n",
    "#Train and test model for all CVs splits\n",
    "for sheet in ['CV1','CV2','CV3','CV4','CV5','CV6','CV7','CV8','CV9','CV10']:\n",
    "    if True:\n",
    "        print(sheet)\n",
    "        sheet_name = sheet\n",
    "        long_term_outcome = pd.read_excel(outcome_sheet_all, sheet_name = sheet)\n",
    "        \n",
    "        Train_dict = {}\n",
    "        Val_dict = {}\n",
    "        Test_dict = {}\n",
    "        \n",
    "        #get train and validation splits\n",
    "        for index, row in long_term_outcome.iterrows():\n",
    "            if index >= 0:     \n",
    "                split_num = row['split_num']\n",
    "                if split_num == 0:\n",
    "                    Train_dict[str(row['patient'])] = 1\n",
    "                    \n",
    "                elif split_num == 1:\n",
    "                    Val_dict[str(row['patient'])] = 1\n",
    "                    \n",
    "        #initialize traiinng and validaiton panda frames for train/validation\n",
    "        Train_pd = pd.DataFrame()\n",
    "        Train_Y = pd.Series()\n",
    "        Val_pd = pd.DataFrame()\n",
    "        Val_Y = pd.Series()\n",
    "\n",
    "        #populate training and validation inputs/outputs\n",
    "        count = 0\n",
    "        for index, row in features_filtered_no_colnr_norm.iterrows():\n",
    "            MAP_features = features_filtered_no_colnr_norm.iloc[[count]]\n",
    "            MAP_label = all_y_series.iloc[[count]]\n",
    "            patient_id = str(index)[:5]\n",
    "            if patient_id in Train_dict.keys():\n",
    "                Train_pd = Train_pd.append(MAP_features)\n",
    "                Train_Y = Train_Y.append(MAP_label)\n",
    "            elif patient_id in Val_dict.keys():\n",
    "                Val_pd = Val_pd.append(MAP_features)\n",
    "                Val_Y = Val_Y.append(MAP_label)\n",
    "            count += 1\n",
    "        \n",
    "        #get features with highest coefficients - in absolute value\n",
    "        topFeaturesIdx = np.argsort(np.abs(logReg_coef[0,:]))[-numberOfFeatures:]\n",
    "\n",
    "        #remove all features but top x coefficients as selected from train/val inputs\n",
    "        Train_pd_top = Train_pd.iloc[:,topFeaturesIdx]\n",
    "        Val_pd_top = Val_pd.iloc[:,topFeaturesIdx]\n",
    "\n",
    "        #SVC model\n",
    "        from sklearn.svm import SVC\n",
    "        svc_model = SVC(kernel='linear', C=1).fit(Train_pd_top,Train_Y)#train model\n",
    "\n",
    "        #get model predictions for train/val datasets\n",
    "        y_pred_Train_Features = svc_model.predict(Train_pd_top)\n",
    "        y_pred_Val_Features = svc_model.predict(Val_pd_top)\n",
    "    \n",
    "        #calculate metrics for results\n",
    "        from calc_metrics_v2 import calc_classification_metrics\n",
    "        \n",
    "        Train_met_Features = calc_classification_metrics(Train_Y.values,y_pred_Train_Features)\n",
    "        Val_met_Features = calc_classification_metrics(Val_Y.values,y_pred_Val_Features)\n",
    "\n",
    "        #popiulate and save results\n",
    "        SVM_results_Train = SVM_results_Train.append({'num of top features': numberOfFeatures, 'Cross Validation': sheet, 'split': 'Train', \n",
    "                                          'Accuracy':Train_met_Features[1], 'Sensitivity':Train_met_Features[2], \n",
    "                                          'Specificity':Train_met_Features[3], 'PPV':Train_met_Features[4], \n",
    "                                          'NPV':Train_met_Features[5]}, ignore_index=True)\n",
    "        SVM_results_Val = SVM_results_Val.append({'num of top features': numberOfFeatures, 'Cross Validation': sheet, 'split': 'Val', \n",
    "                                          'Accuracy':Val_met_Features[1], 'Sensitivity':Val_met_Features[2], \n",
    "                                          'Specificity':Val_met_Features[3], 'PPV':Val_met_Features[4], \n",
    "                                          'NPV':Val_met_Features[5]}, ignore_index=True)\n",
    "        \n",
    "        Val_results = Val_Y.to_frame()\n",
    "        Val_results = Val_results.rename(columns={0: \"True Labels\"})\n",
    "        Val_results['Predicted Labels'] = y_pred_Val_Features\n",
    "        \n",
    "        Train_results = Train_Y.to_frame()\n",
    "        Train_results = Train_results.rename(columns={0: \"True Labels\"})\n",
    "        Train_results['Predicted Labels'] = y_pred_Train_Features\n",
    "        \n",
    "        Val_results.to_excel(writer, sheet_name='Validation single labels '+ sheet)\n",
    "        Train_results.to_excel(writer, sheet_name='Training single labels '+ sheet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save results to Excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write each dataframe to a different worksheet.\n",
    "SVM_results_Val.to_excel(writer, sheet_name='Results_Val')\n",
    "SVM_results_Train.to_excel(writer, sheet_name='Results_Train')\n",
    "\n",
    "# Close the Pandas Excel writer and output the Excel file.\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
